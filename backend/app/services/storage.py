from pathlib import Path
import json
from typing import List, Dict, Any

from ask_forge.backend.app.constants import PAGES_JSON_DIR

def write_pages_json(index_name: str, all_chunks: List[Dict[str, Any]]) -> Path:
    """
    Write processed document chunks to a JSON file inside the configured pages directory.

    Each indexed document (or collection of chunks) is saved as a separate JSON file
    named after the given `index_name`. The output is formatted for readability and uses
    UTF-8 encoding.

    Args:
        index_name (str):
            Logical name of the index or dataset (e.g., "econ101_notes").
            This will determine the output file name: `{index_name}.json`.
        all_chunks (List[Dict[str, Any]]):
            A list of document chunk objects, typically generated by
            the `split_and_filter()` or `extract_all_chunks()` pipeline.
            Example of each element:
            ```python
            {
                "source": "lecture1.pdf",
                "content": [
                    {"text": "Some text...", "page": 1, "chunk_id": "p1_c1"},
                    {"text": "More text...", "page": 1, "chunk_id": "p1_c2"}
                ]
            }
            ```

    Returns:
        Path:
            The absolute path to the created JSON file.

    Side Effects:
        - Creates the parent directory if it does not exist.
        - Overwrites existing file with the same name.

    Example:
        >>> out_path = write_pages_json("management_theory", all_chunks)
        >>> print(f"Saved {len(all_chunks)} files to:", out_path)

    Notes:
        - The file path is based on `PAGES_JSON_DIR`, imported from constants.
        - This function is part of the backend persistence layer for AskForge indexing.
    """
    out_file = PAGES_JSON_DIR / f"{index_name}.json"
    out_file.parent.mkdir(parents=True, exist_ok=True)
    with out_file.open("w", encoding="utf-8") as f:
        json.dump(all_chunks, f, ensure_ascii=False, indent=4)
    return out_file


def read_pages_json(index_name: str) -> List[Dict[str, Any]]:
    """
    Read a previously saved JSON file containing document chunks.

    This function is the inverse of `write_pages_json()`: it retrieves
    preprocessed chunks from the local JSON store for reuse, re-indexing,
    or verification.

    Args:
        index_name (str):
            Logical name of the JSON file to read (without the `.json` extension).
            Example: `"econ101_notes"` â†’ reads `PAGES_JSON_DIR/econ101_notes.json`.

    Returns:
        List[Dict[str, Any]]:
            A list of parsed JSON objects containing chunk metadata and text.
            Returns an empty list (`[]`) if the file does not exist.

    Example:
        >>> data = read_pages_json("management_theory")
        >>> print("Loaded chunks:", len(data))

    Notes:
        - Gracefully handles missing files by returning an empty list.
        - Useful for reloading indexed data without reprocessing PDFs.
    """
    p = PAGES_JSON_DIR / f"{index_name}.json"
    if not p.exists():
        return []
    with p.open("r", encoding="utf-8") as f:
        return json.load(f)
